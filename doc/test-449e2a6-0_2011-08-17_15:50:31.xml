<?xml version='1.0' ?>
<?xml-stylesheet href="TestResults.xsl" type="text/xsl" ?>
<MPITESTRESULTS>
<DATE>2011-08-17-15-50</DATE>
<MPISOURCE></MPISOURCE>
<MPITEST>
<NAME>attrt</NAME>
<NP>2</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attric</NAME>
<NP>4</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrerr</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrend</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrend</NAME>
<NP>4</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrend2</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrend2</NAME>
<NP>5</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrerrcomm</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrerrtype</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attr2type</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrorder</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrordercomm</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrordertype</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattr2</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrcomm</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyval</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvalcomm</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvaltype</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>keyval_double_free</NAME>
<NP>1</NP>
<WORKDIR>./attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./allred): No such file or directory"
Could not spawn './allred' process 0: No such file or directory
Could not spawn './allred' process 1: No such file or directory
Could not spawn './allred' process 2: No such file or directory
Could not spawn './allred' process 3: No such file or directory
Could not spawn './allred' process 4: No such file or directory
Could not spawn './allred' process 5: No such file or directory
Could not spawn './allred' process 6: No such file or directory
startProcs: PSI_spawn() failed.
Unable to start all processes. Aborting.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>allred</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allredmany</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred4</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred5</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allred5</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reduce</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reduce</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reduce_local</NAME>
<NP>2</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>op_commutative</NAME>
<NP>2</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red4</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoall1</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallv</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallv0</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw1</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw_zeros</NAME>
<NP>1</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw_zeros</NAME>
<NP>2</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw_zeros</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw_zeros</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allgather2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allgather3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allgatherv2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allgatherv3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allgatherv4</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bcasttest</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bcasttest</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bcasttest</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bcast2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bcast2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
PSI: handleAnswer: spawn to node 15 failed: "testExecutable: stat(./bcast2): No such file or directory"
Could not spawn './bcast2' process 0: No such file or directory
Could not spawn './bcast2' process 1: No such file or directory
Could not spawn './bcast2' process 2: No such file or directory
Could not spawn './bcast2' process 3: No such file or directory
Could not spawn './bcast2' process 4: No such file or directory
Could not spawn './bcast2' process 5: No such file or directory
Could not spawn './bcast2' process 6: No such file or directory
Could not spawn './bcast2' process 7: No such file or directory
Could not spawn './bcast2' process 8: No such file or directory
Could not spawn './bcast2' process 9: No such file or directory
startProcs: PSI_spawn() failed.
Unable to start all processes. Aborting.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>bcast3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll2</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll3</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll4</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll5</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll6</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll7</NAME>
<NP>1</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll7</NAME>
<NP>2</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll7</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll8</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll9</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll10</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll11</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll12</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>coll13</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>longuser</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat</NAME>
<NP>6</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat2</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscat3</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscatinter</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block2</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>red_scat_block2</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscatblk3</NAME>
<NP>8</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>redscatblk3</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scantst</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exscan</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exscan2</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gather</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gather2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scattern</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scatter2</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scatter3</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scatterv</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbcast</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbcast</NAME>
<NP>10</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallreduce</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallreduce</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icreduce</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icreduce</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscatter</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscatter</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgather</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgather</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgather</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgather</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbarrier</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbarrier</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgatherv</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgatherv</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgatherv</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgatherv</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscatterv</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscatterv</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoall</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoall</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoallv</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoallv</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoallw</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoallw</NAME>
<NP>7</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opland</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>oplor</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>oplxor</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>oplxor</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opband</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opbor</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opbxor</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opbxor</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opprod</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opprod</NAME>
<NP>6</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opsum</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opmin</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opminloc</NAME>
<NP>4</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opmax</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>opmaxloc</NAME>
<NP>5</NP>
<WORKDIR>./coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dup</NAME>
<NP>2</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dupic</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commcreate1</NAME>
<NP>8</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commname</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ic1</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgroup</NAME>
<NP>8</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icm</NAME>
<NP>8</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icsplit</NAME>
<NP>8</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>iccreate</NAME>
<NP>8</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ctxalloc</NAME>
<NP>2</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ctxsplit</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cmfree</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cmsplit</NAME>
<NP>4</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cmsplit2</NAME>
<NP>12</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>probe-intercomm</NAME>
<NP>2</NP>
<WORKDIR>./comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contents</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gaddress</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>lbub</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>localpack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>simple-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>slice-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typecommit</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typename</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typefree</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>zeroparms</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>getpartelm</NAME>
<NP>2</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>tresized</NAME>
<NP>2</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>tresized2</NAME>
<NP>2</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>tmatchsize</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>tfree</NAME>
<NP>2</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typelb</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contigstruct</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-zero-count</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>blockindexed-zero-count</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>blockindexed-misc</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>indexed-misc</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>subarray-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>subarray</NAME>
<NP>2</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>darray-pack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>darray-pack</NAME>
<NP>9</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>pairtype-size-extent</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>simple-commit</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>simple-size-extent</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-no-real-types</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-empty-el</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contig-zero-count</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>simple-resized</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>unusual-noncontigs</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>hindexed-zeros</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>lots-of-types</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>get-elements-pairtype</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>unpack</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-ezhov</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>zeroblks</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-derived-zeros</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>struct-verydeep</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>get-elements</NAME>
<NP>1</NP>
<WORKDIR>./datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>adderr</NAME>
<NP>1</NP>
<WORKDIR>./errhan</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commcall</NAME>
<NP>2</NP>
<WORKDIR>./errhan</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>errfatal</NAME>
<NP>1</NP>
<WORKDIR>./errhan</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>groupcreate</NAME>
<NP>4</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>grouptest</NAME>
<NP>8</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>grouptest2</NAME>
<NP>4</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>groupnullincl</NAME>
<NP>4</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gtranks</NAME>
<NP>8</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gtranksperf</NAME>
<NP>20</NP>
<WORKDIR>./group</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infodup</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infodel</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infovallen</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infoorder</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infomany</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infomany2</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infotest</NAME>
<NP>1</NP>
<WORKDIR>./info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exitst1</NAME>
<NP>2</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exitst2</NAME>
<NP>4</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>initstat</NAME>
<NP>1</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>timeout</NAME>
<NP>2</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 10 seconds elapsed.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>version</NAME>
<NP>1</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>finalized</NAME>
<NP>1</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrself</NAME>
<NP>1</NP>
<WORKDIR>./init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendrecv1</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendrecv2</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendrecv3</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendflood</NAME>
<NP>8</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendself</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendall</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>anyall</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>eagerdt</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>pingping</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bottom</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend1</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend2</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend3</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend4</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend5</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsendalign</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsendpending</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>isendself</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsendfrag</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icsend</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>rqstatus</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>rqfreeb</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>greq1</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>probe-unexp</NAME>
<NP>4</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>probenull</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>scancel</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Failed to cancel an Isend request
Failed to cancel an Ibsend request
Failed to cancel an Isend request
Failed to cancel an Ibsend request
Failed to cancel an Isend request
Failed to cancel an Ibsend request
Failed to cancel an Isend request
Failed to cancel an Ibsend request
 Found 8 errors
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>scancel2</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>pscancel</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Failed to cancel a persistent send request
Failed to cancel a persistent bsend request
Failed to cancel a persistent send request
Failed to cancel a persistent bsend request
Failed to cancel a persistent send request
Failed to cancel a persistent bsend request
Failed to cancel a persistent send request
Failed to cancel a persistent bsend request
 Found 8 errors
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>rcancel</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cancelrecv</NAME>
<NP>2</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>isendselfprobe</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>inactivereq</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>waittestnull</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>waitany-null</NAME>
<NP>1</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>large_message</NAME>
<NP>3</NP>
<WORKDIR>./pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winname</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allocmem</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>putfence1</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 12559 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x6079d0 listen:    -1 demand:   0(   0)  src:(192.168.42.15,12559,(nil),r0000003)
  Connections:
    con#0x6110f0 type:  loop state:    open dest:(192.168.42.15,12559,0x6110f0,r0000003) recvcnt:    0
    con#0x611280 type:   shm state:    open dest:(192.168.42.15,12555,0x611280,r0000000) recvcnt:    0
    con#0x611410 type:   shm state:    open dest:(192.168.42.15,12558,0x611410,r0000002) recvcnt:    0
    con#0x6115a0 type:   shm state:    open dest:(192.168.42.15,12557,0x6116c0,r0000001) recvcnt:    0
Fds:

Reqs:7 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 3 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>putfidx</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 12569 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x6079d0 listen:    -1 demand:   0(   0)  src:(192.168.42.15,12569,(nil),r0000003)
  Connections:
    con#0x6110f0 type:  loop state:    open dest:(192.168.42.15,12569,0x6110f0,r0000003) recvcnt:    0
    con#0x611280 type:   shm state:    open dest:(192.168.42.15,12565,0x611280,r0000000) recvcnt:    0
    con#0x611410 type:   shm state:    open dest:(192.168.42.15,12568,0x611410,r0000002) recvcnt:    0
    con#0x6115a0 type:   shm state:    open dest:(192.168.42.15,12567,0x6116c0,r0000001) recvcnt:    0
Fds:

Reqs:7 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 3 exited with status 112.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>getfence1</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>accfence1</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 12589 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x6079d0 listen:    -1 demand:   0(   0)  src:(192.168.42.15,12589,(nil),r0000003)
  Connections:
    con#0x6110f0 type:  loop state:    open dest:(192.168.42.15,12589,0x6110f0,r0000003) recvcnt:    0
    con#0x611280 type:   shm state:    open dest:(192.168.42.15,12585,0x611280,r0000000) recvcnt:    0
    con#0x611410 type:   shm state:    open dest:(192.168.42.15,12588,0x611410,r0000002) recvcnt:    0
    con#0x6115a0 type:   shm state:    open dest:(192.168.42.15,12587,0x6116c0,r0000001) recvcnt:    0
Fds:

Reqs:7 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 3 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>adlb_mimic1</NAME>
<NP>3</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>accfence2</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 12608 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x6079d0 listen:    -1 demand:   0(   0)  src:(192.168.42.15,12608,(nil),r0000000)
  Connections:
    con#0x6110f0 type:  loop state:    open dest:(192.168.42.15,12608,0x6110f0,r0000000) recvcnt:    0
    con#0x611280 type:   shm state:    open dest:(192.168.42.15,12612,0x611280,r0000003) recvcnt:    0
    con#0x611410 type:   shm state:    open dest:(192.168.42.15,12610,0x611410,r0000001) recvcnt:    0
    con#0x6115a0 type:   shm state:    open dest:(192.168.42.15,12611,0x6115a0,r0000002) recvcnt:    0
Fds:

Reqs:11 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 0 exited with status 112.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>putpscw1</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>getgroup</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose1</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose2</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose3</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose5</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose6</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>transpose7</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test1</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test2</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test3</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test4</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test5</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>lockcontention</NAME>
<NP>3</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>lockcontention2</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>lockcontention2</NAME>
<NP>8</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
PSIlogger: Child with rank 7 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>transpose4</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fetchandadd</NAME>
<NP>7</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 5 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>fetchandadd_tree</NAME>
<NP>7</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 5 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>wintest</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contig_displ</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test1_am</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test2_am</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test3_am</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test4_am</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test5_am</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fetchandadd_am</NAME>
<NP>7</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 5 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>fetchandadd_tree_am</NAME>
<NP>7</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 5 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>accfence2_am</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>test1_dt</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>nullpscw</NAME>
<NP>7</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrorderwin</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>wincall</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrwin</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvalwin</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>selfrma</NAME>
<NP>1</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>mixedsync</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
PSIlogger: Maximum runtime of 180 seconds elapsed.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>epochtest</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 13069 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x6079d0 listen:    -1 demand:   0(   0)  src:(192.168.42.15,13069,(nil),r0000003)
  Connections:
    con#0x6110f0 type:  loop state:    open dest:(192.168.42.15,13069,0x6110f0,r0000003) recvcnt:    0
    con#0x611280 type:   shm state:    open dest:(192.168.42.15,13066,0x611280,r0000000) recvcnt:    0
    con#0x611410 type:   shm state:    open dest:(192.168.42.15,13068,0x611410,r0000002) recvcnt:    0
    con#0x6115a0 type:   shm state:    open dest:(192.168.42.15,13067,0x6115a0,r0000001) recvcnt:    0
Fds:

Reqs:7 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 3 exited with status 112.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>locknull</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>rmanull</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>strided_acc_indexed</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>strided_acc_onelock</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>strided_acc_subarray</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>strided_get_indexed</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>strided_putget_indexed</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>window_creation</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contention_put</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>contention_putget</NAME>
<NP>4</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>put_base</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>put_bottom</NAME>
<NP>2</NP>
<WORKDIR>./rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>namepub</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>spawn1</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawn1", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff86b38230, errors=0x7fff86b38220) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawn2</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawn2", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff4310dcf0, errors=0x7fff4310dce0) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawninfo1</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="spawninfo1", argv=(nil), maxprocs=2, info=0x9c000000, root=0, MPI_COMM_WORLD, intercomm=0x7fff92e33b10, errors=0x7fff92e33b00) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnminfo1</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x7fff99b373e0, argvs=(nil), maxprocs=0x7fff99b37410, infos=0x7fff99b373f0, root=0, MPI_COMM_WORLD, intercomm=0x7fff99b37420, errors=0x7fff99b37400) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnintra</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintra", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffeb0d8b60, errors=0x7fffeb0d8b30) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnintra</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintra", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff85824b20, errors=0x7fff85824af0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintra", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff2303cfc0, errors=0x7fff2303cf90) failed
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnargv</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnargv", argv=0x7fffa9c4a3e0, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffa9c4a440, errors=0x7fffa9c4a430) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmanyarg</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnmanyarg", argv=0x7fff672e9780, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff672eb794, errors=0x7fff672eb780) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmult2</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x606200, argvs=(nil), maxprocs=0x606210, infos=0x6061f0, root=0, MPI_COMM_WORLD, intercomm=0x7fff2023cfc8, errors=0x7fff2023cf90) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x606200, argvs=(nil), maxprocs=0x606210, infos=0x6061f0, root=0, MPI_COMM_WORLD, intercomm=0x7fff10a10098, errors=0x7fff10a10060) failed
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spaconacc</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
MPI_Comm_spawn failed: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="spaconacc", argv=0x7fff3d33d180, maxprocs=1, info=0x9c000000, root=0, MPI_COMM_SELF, intercomm=0x7fff3d33d1a4, errors=(nil)) failed
(unknown)(): Unsupported file operation 
PSIlogger: Child with rank 0 exited with status 44.
application called MPI_Abort(MPI_COMM_WORLD, 1006716972) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spaconacc2</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="spaconacc2", argv=0x7fff8dcdfdc0, maxprocs=1, info=0x9c000000, root=0, MPI_COMM_SELF, intercomm=0x7fff8dcdfdf0, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>selfconacc</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
MPI_Open_port failed: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x7fffe5123290) failed
(unknown)(): Unsupported file operation 
Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fffbf2b35f0, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fffbf2b36f0) failed

PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 44.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneapplication called MPI_Abort(MPI_COMM_WORLD, 402756908) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spaiccreate</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spaiccreate", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_SELF, intercomm=0x7fff1f848d30, errors=0x7fff1f848d10) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in PMPI_Intercomm_create: Other MPI error, error stack:
PMPI_Intercomm_create(577)....: MPI_Intercomm_create(MPI_COMM_WORLD, local_leader=0, MPI_COMM_NULL, remote_leader=0, tag=123, newintercomm=0x7fff96421bbc) failed
PMPI_Intercomm_create(439)....: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>taskmaster</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./taskmaster", argv=(nil), maxprocs=1, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x6110e0, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>taskmaster</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./taskmaster", argv=(nil), maxprocs=1, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x611290, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./taskmaster", argv=(nil), maxprocs=1, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x611290, errors=(nil)) failed
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>join</NAME>
<NP>2</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Warning: MPID_Open_port() not implemented
Error in MPI_Comm_join 671694892
Error in MPI_Comm_join 201932844
Error in MPI_Sendrecv on new communicator
Error in MPI_Sendrecv on new communicator
Error in MPI_Comm_disconnect
Error in MPI_Comm_disconnect
 Found 2054 errors
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect_reconnect</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect", argv=0x7fff78e98c50, maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff78e98b28, errors=(nil)) failed
PSIlogger: Child with rank 1 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect", argv=0x7fff4db58170, maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff4db58048, errors=(nil)) failed
PSIlogger: Child with rank 2 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect", argv=0x7fff39207b00, maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff392079d8, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect_reconnect2</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="disconnect_reconnect2", argv=0x7fffbb986e50, maxprocs=3, info=0x9c000000, root=0, MPI_COMM_WORLD, intercomm=0x7fffbb986e84, errors=(nil)) failed
PSIlogger: Child with rank 1 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="disconnect_reconnect2", argv=0x7fffae3bb0d0, maxprocs=3, info=0x9c000000, root=0, MPI_COMM_WORLD, intercomm=0x7fffae3bb104, errors=(nil)) failed
PSIlogger: Child with rank 2 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="disconnect_reconnect2", argv=0x7fff00499a90, maxprocs=3, info=0x9c000000, root=0, MPI_COMM_WORLD, intercomm=0x7fff00499ac4, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect_reconnect3</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect3", argv=0x7ffff381ba20, maxprocs=4, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7ffff381b8fc, errors=(nil)) failed
PSIlogger: Child with rank 2 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect3", argv=0x7fffde83e9b0, maxprocs=4, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffde83e88c, errors=(nil)) failed

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect_reconnect3", argv=0x7fffbddbd550, maxprocs=4, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffbddbd42c, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>multiple_ports</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x7fff266b6bb0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fffc7734720, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fffc7734920) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fff3a14f6a0, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fff3a14f7a0) failed
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>multiple_ports2</NAME>
<NP>4</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x7fff072ca5e0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fff1fe5c2c0, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fff1fe5c5c0) failed
PSIlogger: Child with rank 3 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fffaa6f9bf0, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fffaa6f9cf0) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fff4b392660, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x7fff4b392860) failed
PSIlogger: Child with rank 2 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff28832b5c, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffc21ce35c, errors=(nil)) failed

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff693ff08c, errors=(nil)) failed
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect2</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect2", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffd337e5f4, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect2", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffd9be3804, errors=(nil)) failed
PSIlogger: Child with rank 1 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect2", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffc2639754, errors=(nil)) failed
PSIlogger: Child with rank 2 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>disconnect3</NAME>
<NP>3</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect3", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff66d5a9d4, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect3", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff8ab5e674, errors=(nil)) failed

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./disconnect3", argv=(nil), maxprocs=3, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff109dc234, errors=(nil)) failed
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>concurrent_spawns</NAME>
<NP>1</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./concurrent_spawns", argv=0x7fff7273e280, maxprocs=1, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff7273e2c0, errors=(nil)) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>pgroup_connect_test</NAME>
<NP>4</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x611600) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x611600, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>pgroup_intercomm_test</NAME>
<NP>4</NP>
<WORKDIR>./spawn</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartmap1</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartzero</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartshift1</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartsuball</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartcreates</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dims1</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dims2</NAME>
<NP>1</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>graphmap1</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>topotest</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>topodup</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>graphcr</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>graphcr2</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>distgraph1</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dgraph_unwgt</NAME>
<NP>4</NP>
<WORKDIR>./topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>rdwrord</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>rdwrzero</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>getextent</NAME>
<NP>2</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>setinfo</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>setviewcur</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fff0a94d8e4, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 

mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fffdf257354, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>i_noncontig</NAME>
<NP>2</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 19996
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1ADIOI_Set_lock:offset 0, length 19996
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>async</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 1 exited with status 1.


application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>async_any</NAME>
<NP>4</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 65536
PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>userioerr</NAME>
<NP>1</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>resized</NAME>
<NP>1</NP>
<WORKDIR>./io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 16
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>baseattrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattr2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattr2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattr3f</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattr2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattr3f</NAME>
<NP>1</NP>
<WORKDIR>./f77/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uallreducef</NAME>
<NP>4</NP>
<WORKDIR>./f77/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exscanf</NAME>
<NP>5</NP>
<WORKDIR>./f77/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallwf</NAME>
<NP>7</NP>
<WORKDIR>./f77/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>inplacef</NAME>
<NP>4</NP>
<WORKDIR>./f77/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reducelocalf</NAME>
<NP>2</NP>
<WORKDIR>./f77/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typenamef</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typesnamef</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typecntsf</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typem2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typesubf</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>packef</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gaddressf</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allctypesf</NAME>
<NP>1</NP>
<WORKDIR>./f77/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>statusesf</NAME>
<NP>1</NP>
<WORKDIR>./f77/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>greqf</NAME>
<NP>1</NP>
<WORKDIR>./f77/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infotestf</NAME>
<NP>1</NP>
<WORKDIR>./f77/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infotest2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>namepubf</NAME>
<NP>2</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>spawnf</NAME>
<NP>1</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnf", argv=0x614690, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff5fb1ebf0, errors=0x7fff5fb1ec00) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnargvf</NAME>
<NP>1</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnargvf", argv=0x614690, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff438517d0, errors=0x7fff438517e0) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>connaccf</NAME>
<NP>2</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x614ae0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmultf</NAME>
<NP>1</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e600, argvs=0x614700, maxprocs=0x7fffe1064360, infos=0x7fffe1064370, root=0, MPI_COMM_WORLD, intercomm=0x7fffe106436c, errors=0x7fffe1064390) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmult2f</NAME>
<NP>2</NP>
<WORKDIR>./f77/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e610, argvs=(nil), maxprocs=0x7fff686e2970, infos=0x7fff686e2980, root=0, MPI_COMM_WORLD, intercomm=0x7fff686e297c, errors=0x7fff686e29a0) failed
PSIlogger: Child with rank 1 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e610, argvs=(nil), maxprocs=0x7fff2a1c9400, infos=0x7fff2a1c9410, root=0, MPI_COMM_WORLD, intercomm=0x7fff2a1c940c, errors=0x7fff2a1c9430) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwriteatf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:offset 8, length 4

PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.


application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwritef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 2 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwriteshf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=0, tag=1, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=2, tag=1, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=1, tag=1, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 2 exited with status 1.


application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeshf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=0, tag=1, MPI_COMM_WORLD, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=2, tag=1, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x643220, count=0, MPI_INTEGER, src=1, tag=1, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallbef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 2 exited with status 1.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallbef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 2 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordbef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>fileerrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fileinfof</NAME>
<NP>3</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>shpositionf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneapplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>atomicityf</NAME>
<NP>8</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 40000
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 4 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fff21268d80) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 

mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fff2a9c3f70) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 

mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fff005e2890) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 
PSIlogger: Child with rank 6 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fffa1cbdd20) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
PSIlogger: Child with rank 5 exited with status 1.
PSIlogger: Child with rank 7 exited with status 1.
MPIR_Get_contextid_sparse(572): Too many communicators
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>miscfilef</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3ADIOI_Set_lock:offset 0, length 4096

PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

PSIlogger: Child with rank 1 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>setviewcurf</NAME>
<NP>4</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fff15556d34, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 

mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fff29c0ed74, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2f2ciof</NAME>
<NP>1</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>c2fmultio</NAME>
<NP>1</NP>
<WORKDIR>./f77/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winscale1f</NAME>
<NP>4</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winfencef</NAME>
<NP>4</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 13909 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,13909,(nil),r0000001)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,13909,0x6146a0,r0000001) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,13910,0x614830,r0000002) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,13907,0x6149c0,r0000000) recvcnt:    0
    con#0x614c70 type:   shm state:    open dest:(192.168.42.15,13911,0x614b50,r0000003) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
Deadlock detected! Process 13910 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,13910,(nil),r0000002)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,13910,0x6146a0,r0000002) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,13909,0x614830,r0000001) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,13911,0x6149c0,r0000003) recvcnt:    0
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,13907,0x614b50,r0000000) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 1 exited with status 112.
PSIlogger: Child with rank 2 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>wingetf</NAME>
<NP>5</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winscale2f</NAME>
<NP>4</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winerrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winnamef</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>wingroupf</NAME>
<NP>4</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winaccf</NAME>
<NP>4</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 13959 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,13959,(nil),r0000001)
  Connections:
Deadlock detected! Process 13960 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,13960,(nil),r0000002)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,13959,0x6146a0,r0000001) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,13960,0x614830,r0000002) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,13957,0x6149c0,r0000000) recvcnt:    0
    con#0x614c70 type:   shm state:    open dest:(192.168.42.15,13961,0x614b50,r0000003) recvcnt:    0
Fds:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,13960,0x6146a0,r0000002) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,13959,0x614830,r0000001) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,13961,0x6149c0,r0000003) recvcnt:    0
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,13957,0x614b50,r0000000) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)

Reqs:10 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 1 exited with status 112.
PSIlogger: Child with rank 2 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2f2cwinf</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrwinf</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winattrf</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winattr2f</NAME>
<NP>1</NP>
<WORKDIR>./f77/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseenvf</NAME>
<NP>1</NP>
<WORKDIR>./f77/init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commnamef</NAME>
<NP>2</NP>
<WORKDIR>./f77/comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commerrf</NAME>
<NP>2</NP>
<WORKDIR>./f77/comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>c2f2cf</NAME>
<NP>1</NP>
<WORKDIR>./f77/ext</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>

c2f2cf:13997 terminated with signal 11 at PC=2b3e894abcfe SP=7fff0d2094d8.  Backtrace:
/opt/parastation/lib64/libpscom.so(_pscom_recvq_user_is_inside+0xe)[0x2b3e894abcfe]
/opt/parastation/lib64/libpscom.so(pscom_cancel_recv+0xc8)[0x2b3e894a1518]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPID_Cancel_recv+0x12)[0x2b3e87eaee62]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPIR_Cancel_impl+0x9d)[0x2b3e87e7352d]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPI_Cancel+0xe0)[0x2b3e87e73770]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(pmpi_cancel+0x9)[0x2b3e87e73489]
./c2f2cf[0x401dda]
./c2f2cf[0x402a9c]
/lib64/libc.so.6(__libc_start_main+0xe6)[0x2b3e88929bc6]
./c2f2cf[0x4016e9]
PSIlogger: Child with rank 0 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2fmult</NAME>
<NP>1</NP>
<WORKDIR>./f77/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ctypesinf</NAME>
<NP>1</NP>
<WORKDIR>./f77/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allocmemf</NAME>
<NP>1</NP>
<WORKDIR>./f77/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartcrf</NAME>
<NP>4</NP>
<WORKDIR>./f77/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dgraph_wgtf</NAME>
<NP>4</NP>
<WORKDIR>./f77/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dgraph_unwgtf</NAME>
<NP>4</NP>
<WORKDIR>./f77/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attrtx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>attricx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrcommx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvalcommx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvaltypex</NAME>
<NP>1</NP>
<WORKDIR>./cxx/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>bsend1cxx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sendrecvx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commname2</NAME>
<NP>4</NP>
<WORKDIR>./cxx/comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>arcomplex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uallredx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uallreduce</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ureduce</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uscan</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uexscan</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallw2x</NAME>
<NP>10</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbcastx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbcastx</NAME>
<NP>10</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallreducex</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icreducex</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscatterx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgatherx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgatherx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icbarrierx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icallgathervx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icgathervx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icscattervx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>icalltoallx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reduceboolx</NAME>
<NP>5</NP>
<WORKDIR>./cxx/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commcallx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/errhan</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseenv</NAME>
<NP>1</NP>
<WORKDIR>./cxx/init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>initstatx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>initstat2x</NAME>
<NP>1</NP>
<WORKDIR>./cxx/init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infodupx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infodelx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infovallenx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infoorderx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>packsizex</NAME>
<NP>1</NP>
<WORKDIR>./cxx/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typecntsx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typenamex</NAME>
<NP>1</NP>
<WORKDIR>./cxx/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typemiscx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>iwriteatx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

PSIlogger: Child with rank 1 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwritex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 2 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwriteshx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=1, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=2, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 2 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 3 exited with status 1.

PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeshx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=1, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=2, tag=0, MPI_COMM_WORLD, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallbex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 3 exited with status 1.


application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallbex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 0 exited with status 1.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordbex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwriteatnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4

PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwritenosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 3 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 1 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>iwriteshnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed

PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneapplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=2, tag=0, MPI_COMM_WORLD, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=1, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writenosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 2 exited with status 1.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 3 exited with status 1.


PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 2 exited with status 1.

PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 2 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeshnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=1, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_INT, src=2, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallnosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 1 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeatallbenosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4
PSIlogger: Child with rank 1 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 2 exited with status 1.

PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeallbenosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 12, length 4
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 4, length 4

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.


application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3ADIOI_Set_lock:offset 8, length 4
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>writeordbenosx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=0, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFile locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=1, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98): read from socket failed - request state:recv(pde)doneFatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=(nil), count=0, MPI_BYTE, src=2, tag=0, comm=0x84000000, status=0x1) failed
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>fileerrx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fileinfox</NAME>
<NP>3</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>filemiscx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
PSIlogger: Child with rank 2 exited with status 1.
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 0 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>shpositionx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 1 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFile locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>seekavail</NAME>
<NP>1</NP>
<WORKDIR>./cxx/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>namepubx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/spawn</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>spawnintrax</NAME>
<NP>1</NP>
<WORKDIR>./cxx/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintrax", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff76212718, errors=0x7fff762126e0) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnintrax</NAME>
<NP>2</NP>
<WORKDIR>./cxx/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintrax", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff46304c48, errors=0x7fff46304c10) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnintrax", argv=(nil), maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffaf943e08, errors=0x7fffaf943dd0) failed
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnargvx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnargvx", argv=0x7fff41d4d160, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff41d4d208, errors=0x7fff41d4d1d0) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>selfconaccx</NAME>
<NP>2</NP>
<WORKDIR>./cxx/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x7fff1c316e60) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Recv: Other MPI error, error stack:
MPI_Recv(186)......: MPI_Recv(buf=0x7fff6b87b690, count=256, MPI_CHAR, src=0, tag=0, MPI_COMM_WORLD, status=0x1) failed
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98): read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>winnamex</NAME>
<NP>1</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>wincallx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>getgroupx</NAME>
<NP>4</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winfencex</NAME>
<NP>4</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 14725 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60b210 listen:    -1 demand:   0(   0)  src:(192.168.42.15,14725,(nil),r0000001)
  Connections:
    con#0x614950 type:  loop state:    open dest:(192.168.42.15,14725,0x614950,r0000001) recvcnt:    0
Deadlock detected! Process 14726 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
    con#0x614ae0 type:   shm state:    open dest:(192.168.42.15,14726,0x614ae0,r0000002) recvcnt:    0
    con#0x614c70 type:   shm state:    open dest:(192.168.42.15,14724,0x614c70,r0000000) recvcnt:    0
    con#0x614e00 type:   shm state:    open dest:(192.168.42.15,14727,0x614e00,r0000003) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
  sock#0x60b210 listen:    -1 demand:   0(   0)  src:(192.168.42.15,14726,(nil),r0000002)
  Connections:
    con#0x614950 type:  loop state:    open dest:(192.168.42.15,14726,0x614950,r0000002) recvcnt:    0
    con#0x614ae0 type:   shm state:    open dest:(192.168.42.15,14725,0x614ae0,r0000001) recvcnt:    0
    con#0x614c70 type:   shm state:    open dest:(192.168.42.15,14727,0x614c70,r0000003) recvcnt:    0
    con#0x614e00 type:   shm state:    open dest:(192.168.42.15,14724,0x614e00,r0000000) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 1 exited with status 112.
PSIlogger: Child with rank 2 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>winscale1x</NAME>
<NP>4</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winscale2x</NAME>
<NP>4</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fkeyvalwinx</NAME>
<NP>1</NP>
<WORKDIR>./cxx/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattr2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattr2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commattr3f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattr2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typeattr3f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fandcattrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/attr</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>uallreducef90</NAME>
<NP>4</NP>
<WORKDIR>./f90/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>exscanf90</NAME>
<NP>5</NP>
<WORKDIR>./f90/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>alltoallwf90</NAME>
<NP>7</NP>
<WORKDIR>./f90/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>inplacef90</NAME>
<NP>4</NP>
<WORKDIR>./f90/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>reducelocalf90</NAME>
<NP>2</NP>
<WORKDIR>./f90/coll</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commnamef90</NAME>
<NP>2</NP>
<WORKDIR>./f90/comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>commerrf90</NAME>
<NP>2</NP>
<WORKDIR>./f90/comm</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>c2f2cf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/ext</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>

c2f2cf90:14857 terminated with signal 11 at PC=2abffd4aacfe SP=7fffc08bf4c8.  Backtrace:
/opt/parastation/lib64/libpscom.so(_pscom_recvq_user_is_inside+0xe)[0x2abffd4aacfe]
/opt/parastation/lib64/libpscom.so(pscom_cancel_recv+0xc8)[0x2abffd4a0518]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPID_Cancel_recv+0x12)[0x2abffbeade62]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPIR_Cancel_impl+0x9d)[0x2abffbe7252d]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(MPI_Cancel+0xe0)[0x2abffbe72770]
/home/partec/psmpi2/build/mpich2/lib/libmpich.so.3(pmpi_cancel+0x9)[0x2abffbe72489]
./c2f2cf90[0x401925]
./c2f2cf90[0x4029fc]
/lib64/libc.so.6(__libc_start_main+0xe6)[0x2abffc927bc6]
./c2f2cf90[0x4016f9]
PSIlogger: Child with rank 0 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2f90mult</NAME>
<NP>1</NP>
<WORKDIR>./f90/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>ctypesinf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allocmemf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/ext</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infotestf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>infotest2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/info</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseenvf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/init</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fileerrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>fileinfof90</NAME>
<NP>3</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>shpositionf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFile locking failed in ADIOI_Set_lock(fd 5,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 8
PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>atomicityf90</NAME>
<NP>8</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 40000
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 4 exited with status 1.

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fffd88a4690) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 

mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 

mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fff343e0530) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
PSIlogger: Child with rank 5 exited with status 1.

mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7ffff88d3040) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
PSIlogger: Child with rank 2 exited with status 1.

MPIR_Get_contextid_sparse(572): Too many communicatorsFatal error in PMPI_Comm_dup: Other MPI error, error stack:
PMPI_Comm_dup(176)............: MPI_Comm_dup(MPI_COMM_WORLD, new_comm=0x7fff1d95a360) failed
PMPI_Comm_dup(161)............: 
MPIR_Comm_dup_impl(55)........: 
MPIR_Comm_copy(967)...........: 
MPIR_Get_contextid(521).......: 
MPIR_Get_contextid_sparse(563): 
MPIR_Allreduce_impl(712)......: 
MPIR_Allreduce_intra(357).....: 
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
MPIR_Allreduce_intra(357).....: 
PSIlogger: Child with rank 7 exited with status 1.
PSIlogger: Child with rank 6 exited with status 1.
mpid_irecv_done(98)...........: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>miscfilef90</NAME>
<NP>4</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 2File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
PSIlogger: Child with rank 2 exited with status 1.
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4096
PSIlogger: Child with rank 1 exited with status 1.

PSIlogger: Child with rank 3 exited with status 1.
application called MPI_Abort(MPI_COMM_WORLD, 1) - process 1application called MPI_Abort(MPI_COMM_WORLD, 1) - process 3
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>setviewcurf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
File locking failed in ADIOI_Set_lock(fd 3,cmd F_SETLKW/7,type F_WRLCK/1,whence 0) with return value FFFFFFFF and errno 25.
- If the file system is NFS, you need to use NFS version 3, ensure that the lockd daemon is running on all the machines, and mount the directory with the 'noac' option (no attribute caching).
- If the file system is LUSTRE, ensure that the directory is mounted with the 'flock' option.
ADIOI_Set_lock:: No locks available
ADIOI_Set_lock:offset 0, length 4
PSIlogger: Child with rank 0 exited with status 1.

application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0Fatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fffd2ba72e4, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 
PSIlogger: Child with rank 2 exited with status 1.

mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)doneFatal error in PMPI_Bcast: Other MPI error, error stack:
PMPI_Bcast(1478)........: MPI_Bcast(buf=0x7fffc2729094, count=1, MPI_INT, root=0, comm=0x84000000) failed
MPIR_Bcast_impl(1321)...: 
MPIR_Bcast_intra(1155)..: 
MPIR_Bcast_binomial(145): 
PSIlogger: Child with rank 1 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
mpid_irecv_done(98).....: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2f2ciof90</NAME>
<NP>1</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>c2f90multio</NAME>
<NP>1</NP>
<WORKDIR>./f90/io</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sizeof2</NAME>
<NP>1</NP>
<WORKDIR>./f90/misc</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>statusesf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>greqf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/pt2pt</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typenamef90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typesnamef90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typecntsf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typem2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>typesubf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>packef90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>gaddressf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>allctypesf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>structf</NAME>
<NP>2</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>indtype</NAME>
<NP>2</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>createf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>sizeof</NAME>
<NP>1</NP>
<WORKDIR>./f90/datatype</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>createf90types</NAME>
<NP>1</NP>
<WORKDIR>./f90/f90types</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>createf90types</NAME>
<NP>1</NP>
<WORKDIR>./f90/f90types</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winscale1f90</NAME>
<NP>4</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winfencef90</NAME>
<NP>4</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 15039 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,15039,(nil),r0000001)
  Connections:
Deadlock detected! Process 15040 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,15040,(nil),r0000002)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,15039,0x6146a0,r0000001) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,15040,0x614830,r0000002) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,15037,0x6149c0,r0000000) recvcnt:    0
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,15041,0x614b50,r0000003) recvcnt:    0
Fds:

    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,15040,0x6146a0,r0000002) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,15039,0x614830,r0000001) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,15041,0x6149c0,r0000003) recvcnt:    0
Reqs:10 GenReqs: (cnt:0  used:0)
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,15037,0x614b50,r0000000) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 1 exited with status 112.
PSIlogger: Child with rank 2 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>wingetf90</NAME>
<NP>5</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winscale2f90</NAME>
<NP>4</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winerrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winnamef90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>wingroupf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winaccf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Deadlock detected! Process 15089 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,15089,(nil),r0000001)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,15089,0x6146a0,r0000001) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,15090,0x614830,r0000002) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,15087,0x6149c0,r0000000) recvcnt:    0
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,15091,0x614b50,r0000003) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
Deadlock detected! Process 15090 will wait forever.
('wait' called without outstanding send or recv requests).
(For single sided communications set PSP_UNEXPECTED_RECEIVES=1)
Requests:
Sockets:
  sock#0x60af60 listen:    -1 demand:   0(   0)  src:(192.168.42.15,15090,(nil),r0000002)
  Connections:
    con#0x6146a0 type:  loop state:    open dest:(192.168.42.15,15090,0x6146a0,r0000002) recvcnt:    0
    con#0x614830 type:   shm state:    open dest:(192.168.42.15,15089,0x614830,r0000001) recvcnt:    0
    con#0x6149c0 type:   shm state:    open dest:(192.168.42.15,15091,0x6149c0,r0000003) recvcnt:    0
    con#0x614b50 type:   shm state:    open dest:(192.168.42.15,15087,0x614b50,r0000000) recvcnt:    0
Fds:

Reqs:10 GenReqs: (cnt:0  used:0)
PSIlogger: Child with rank 1 exited with status 112.
PSIlogger: Child with rank 2 exited with status 112.
PSIlogger: Child with rank 0 exited with status 1.
PSIlogger: Child with rank 3 exited with status 1.
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>c2f2cwinf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>baseattrwinf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winattrf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>winattr2f90</NAME>
<NP>1</NP>
<WORKDIR>./f90/rma</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>namepubf90</NAME>
<NP>2</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>spawnf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnf90", argv=0x614690, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fff2c682300, errors=0x7fff2c682310) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnargvf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn: Unsupported file operation , error stack:
MPI_Comm_spawn(144): MPI_Comm_spawn(cmd="./spawnargvf90", argv=0x6146a0, maxprocs=2, MPI_INFO_NULL, root=0, MPI_COMM_WORLD, intercomm=0x7fffde5648a0, errors=0x7fffde5648b0) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>connaccf90</NAME>
<NP>2</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Open_port() not implemented
Fatal error in PMPI_Open_port: Unsupported file operation , error stack:
PMPI_Open_port(123): MPI_Open_port(MPI_INFO_NULL, port=0x614ae0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in PMPI_Barrier: Other MPI error, error stack:
PMPI_Barrier(425).....: MPI_Barrier(MPI_COMM_WORLD) failed
MPIR_Barrier_impl(331): Failure during collective
MPIR_Barrier_impl(313): 
MPIR_Barrier_intra(83): 
PSIlogger: Child with rank 1 exited with status 1.
mpid_irecv_done(98)...: read from socket failed - request state:recv(pde)done
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmultf90</NAME>
<NP>1</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e610, argvs=0x614710, maxprocs=0x7fff37b9b930, infos=0x7fff37b9b940, root=0, MPI_COMM_WORLD, intercomm=0x7fff37b9b93c, errors=0x7fff37b9b960) failed
PSIlogger: Child with rank 0 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>spawnmult2f90</NAME>
<NP>2</NP>
<WORKDIR>./f90/spawn</WORKDIR>
<STATUS>fail</STATUS>
<TESTDIFF>
Warning: MPID_Comm_spawn_multiple() not implemented
Warning: MPID_Comm_spawn_multiple() not implemented
Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e610, argvs=(nil), maxprocs=0x7fffe79eb6b0, infos=0x7fffe79eb6c0, root=0, MPI_COMM_WORLD, intercomm=0x7fffe79eb6bc, errors=0x7fffe79eb6e0) failed
PSIlogger: Child with rank 0 exited with status 1.

(unknown)(): Unsupported file operation Fatal error in MPI_Comm_spawn_multiple: Unsupported file operation , error stack:
MPI_Comm_spawn_multiple(160): MPI_Comm_spawn_multiple(count=2, cmds=0x60e610, argvs=(nil), maxprocs=0x7ffff624c710, infos=0x7ffff624c720, root=0, MPI_COMM_WORLD, intercomm=0x7ffff624c71c, errors=0x7ffff624c740) failed
PSIlogger: Child with rank 1 exited with status 1.
(unknown)(): Unsupported file operation 
</TESTDIFF>
</MPITEST>
<MPITEST>
<NAME>wtimef90</NAME>
<NP>1</NP>
<WORKDIR>./f90/timer</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>cartcrf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dgraph_wgtf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
<MPITEST>
<NAME>dgraph_unwgtf90</NAME>
<NP>4</NP>
<WORKDIR>./f90/topo</WORKDIR>
<STATUS>pass</STATUS>
</MPITEST>
